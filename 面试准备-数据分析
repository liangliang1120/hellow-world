1、你认为数据分析师的职责是什么？ 
数据分析师的职责包括:
（1）为所有数据分析提供支持，并与客户和员工协调
（2）为客户解决与业务相关的问题，并对数据执行审计
（3）使用统计技术分析结果和解释数据，并提供持续的报告
（4）优先考虑业务需求，并与管理和信息需求紧密合作
（5）确定新的过程或改进机会的领域
（6）分析、识别和解释复杂数据集中的趋势或模式
（7）从主数据源或辅助数据源获取数据并维护数据库/数据系统
（8）过滤和“清理”数据，并检查计算机报告
（9）确定性能指标以定位和纠正代码问题
（10）通过确定用户访问级别来开发访问系统来保护数据库

2、成为一名优秀的数据分析师需要哪些能力？/你认为你有哪些能力可以让你成为一名优秀的数据分析师
 
技术方面：
（1）对报告包(业务对象)、编程语言(XML、Javascript或ETL框架)、数据库(SQL、SQLite等)有丰富的知识。
（2）具有数据库设计、数据模型、数据挖掘和分割技术方面的技术知识。
（3）具备分析大型数据集(SAS, Excel, SPSS等)的统计软件包知识。
能力方面：
具备较强的分析、组织、收集、传播大数据的能力。负责细致，数据感受敏锐，逻辑思维强。

3、请描述数据项目中的主要流程和步骤。

分析项目中的各种步骤包括：问题定义—数据探索—数据准备—构造模型—验证的数据—实施和跟踪

4、你怎样理解数据清洗/数据预处理？

数据清理也称为数据清理，用于识别和消除数据中的错误和不一致性，以提高数据的质量

5、你常用的数据清洗方法有哪些？/你通常在预处理阶段对于数据进行怎样的操作？
 
效果比较好的方法大概有以下几类：
（1）根据不同的属性对数据排序
（2）对于大型数据集，可以逐步对其进行清理，改进数据质量，直到符合期望。
（3）为了提高迭代速度，我常常将大数据集，将它们分解为小数据。
（4）对于常见的清理任务，创建一组实用工具函数/工具/脚本。它可能包括基于CSV文件或SQL数据库重新映射值，
或者借用正则表达式进行搜索和替换，删除所有不匹配正则表达式的值。
（5）如果对数据的清洁度有问题，请按估计的频率排列它们，并解决最常见的问题
（6）从统计指标入手，分析每个列的汇总统计信息，像是标准差、平均值、缺失值等。
（7）跟踪每个日期清理操作，以便在需要时更改或删除操作

6、请解释logistic回归。
 
logistic回归是一种检验数据集的统计方法，其中有一个或多个定义结果的自变量。（或者说是多变量到单变量的映射，清晰合理即可。
 
7、你在进行数据分析时常用哪些工具？
 

Tableau/RapidMiner/OpenRefine/KNIME/Google Search Operators/Solver/NodeXL/io/Wolfram Alpha’s/Google Fusion tables
(结合个人能力，并注意数据分析不同阶段的软件最好都涉及到)
 
8、请说明数据分析（data profiling）和数据挖掘（data mining）之间的区别。
 

data profiling和data mining的区别在于
data profiling:它以单个属性的实例分析为目标。它提供各种属性的信息，如值范围、离散值及其频率、空值的出现、数据类型、长度等。
data mining:侧重于聚类分析、异常记录检测、相关性、序列发现、多个属性之间的关系保持等。
 
9、请列举数据分析师面临的一些常见问题。
 

数据分析师面临的一些常见问题是：常见的拼写错误；重复的条目；缺失值；非法值；不同的值表示；重叠数据的识别
 
10、你知道Apache为在分布式计算环境中处理应用程序的大数据集而开发的框架的名称吗?
 

Hadoop和MapReduce是Apache开发的用于在分布式计算环境中处理应用程序的大型数据集的编程框架。
 
11、描述通常观察到的值缺失的模式是什么?
 

通常被忽略的模式是完全随机缺失、随机缺失、这取决于缺失的值本身、这取决于未观察到的输入变量。
 
12、解释什么是KNN填补法?
 

在KNN注入中，缺失的属性值是通过使用与缺失的属性值最相似的属性值进行注入的。利用距离函数确定两个属性的相似性。
 
13、提到数据分析师使用的数据验证方法是什么?
 

通常，数据分析师用于数据验证的方法是：数据总览，数据验证。
 
14、如何处理可疑或缺失的数据?
 

（1）准备一份提供所有可疑数据信息的验证报告。它应该提供，失败的验证标准以及发生的日期和时间等信息。（这点常常被忽略）
（2）有经验的人员应检查可疑数据以确定其可接受性
（3）应该分配无效数据，并用验证代码替换
（4）对于缺失的数据，可以采用最好的分析策略，如删除法、单一归位法、基于模型的方法等。
 
15、提到如何处理数据多源问题?
 

为了解决多源问题，可以重构模式以完成模式集成，也可以标识类似的记录，并将它们合并到包含所有相关属性的单个记录中，避免冗余。

16、解释什么是异常值?

异常值指的是出现在样本中较远且偏离总体模式的值。有两种类型的异常值：单变量异常值和多元变量异常值。

17、请解释层次聚类法。

层次聚类算法通过构建距离对现有的组进行组合和划分，创建一个层次结构，以显示组的划分或合并顺序。

18、请解释K-means 算法。

K均值是一种著名的划分方法。物体被归为K组中的一组，K组是预先设定的。
在K-mean算法中，聚类结果是球形的且该数据点以该类为中心，集群的方差是相似的:每个数据点属于最近的类。

19、数据分析师需要具有哪些技能？

数据科学家必须具备以下技能：数据库知识、数据库管理、数据融合、查询、数据操作、预测分析、基本描述性统计、
预测建模、先进的分析、大数据的知识、大数据分析、非结构化数据分析、机器学习、演讲技巧、数据可视化、洞察力、报表设计。

20、解释什么是协同过滤?

协同过滤是一种基于用户行为数据创建推荐系统的简单算法。协同过滤最重要的组成部分是用户-项目-兴趣。
协同过滤的一个很好的例子是，当你在网上购物网站上看到像“推荐给你”这样的语句时，它会根据你的浏览历史弹出。

21、列举大数据中的常用工具。
 
Hadoop/Pig/Flume/Mahout/Sqoop

22、请解释KPI、实验设计和二八准则。
 
KPI:它代表关键性能指标，它是一个度量标准，由关于业务流程的电子表格、报告或图表的任何组合组成。
实验设计:是对你的数据进行分割、采样和建立数据进行统计分析的初始过程80/20法则:这意味着你80%的收入来自20%的客户。

23、你知道什么是Map Reduce?
Map-reduce是一个框架，用于处理大型数据集，将它们划分为子集，在不同的服务器上处理每个子集，然后混合在每个服务器上获得的结果。

24、请描述你对于聚类的理解？聚类算法有哪些特性呢？

 
聚类是一种应用于数据的分类方法。聚类算法将数据集分为自然的组或簇。
聚类算法的属性可以是：层次聚类或者水平聚类，迭代聚类，硬聚类和模糊聚类，分隔聚类。
 
25、在数据分析中，常用的统计方法有哪些?
 

对数据科学家有用的统计方法是：贝叶斯方法；马尔可夫过程；空间和聚类过程；排序统计，百分位数，异常值检测；归责技术等。；单纯形法；数学优化。
 
26、什么是时间序列分析?
 

时间序列分析可分为频域分析和时域分析。
在时间序列分析中，利用指数平滑法、对数线性回归法等多种方法，通过对已有数据的分析，可以对特定过程的输出进行预测。
 
27、解释什么是相关图分析?
  

相关图分析是地理学中常见的空间分析形式。
它由一系列为不同空间关系计算的估计自相关系数组成。当原始数据表示为距离而不是单个点的值时，可以使用它来构造基于距离的数据的相关图。
 
28、请解释哈希表/散列表。
 

在计算中，哈希表是键到值的映射。
它是用于实现关联数组的数据结构。它使用哈希函数将索引计算到槽数组中，从中可以获取所需的值。
  
29、什么是哈希表冲突?如何避免?
  

当两个不同的键哈希到相同的值时，就会发生哈希表冲突。数组中的两个数据不能存储在同一个槽中。
解决这个问题常用的方法是：独立的链接和开放寻址。
 
30、解释一个好的数据模型的标准是什么?
  
好的数据模型的标准包括：
它很容易被消费；好的模型中的大型数据更改应该是可伸缩的；它应该提供可预测的性能一个好的模型可以适应需求的变化
